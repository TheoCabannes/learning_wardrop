{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class link:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, name, a0, a1):\n",
    "        self.name = name\n",
    "        self.travel_time = 0 # the travel time of the link\n",
    "        self._flow = 0 # the flow on the link\n",
    "        self._paths = [] # the paths using this link\n",
    "        self._a0 = a0\n",
    "        self._a1 = a1\n",
    "        \n",
    "    def add_path(self, path):\n",
    "        self._paths.append(path)\n",
    "    \n",
    "    def update_flow(self):\n",
    "        self._flow = 0\n",
    "        for path in self._paths:\n",
    "            self._flow += path.flow\n",
    "    \n",
    "    def update_travel_time(self):\n",
    "        self.update_flow()\n",
    "        self.travel_time = self._a0 + self._a1 * self._flow\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class path:\n",
    "    \"\"\"\n",
    "    Notes: \n",
    "     - We should add a method that \"adds a car/updates the flow\" to a path. \n",
    "       This should include the update_travel_time method.\n",
    "     - The travel time of each path shouldn't start at 0, since each path always has some base travel time.\n",
    "       Have the initial travel times of the path be when the congestion is 0. \n",
    "     - When you \"update the travel time\", add what the travel time of each road would be given\n",
    "       the path's current flow.\n",
    "       Maybe each link in the path should only have a function that calculates it's travel time\n",
    "       given a flow on that link.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, links):\n",
    "        self.name = name\n",
    "        self._travel_time = 0 # the travel time of the paths\n",
    "        self.flow = 0 # the flow on the paths\n",
    "        self._links = links # the paths using this link\n",
    "        for link in links:\n",
    "            link.add_path(self)\n",
    "    \n",
    "    # add the marginal cost to see if you converge to the social optimum\n",
    "    def get_travel_time(self):\n",
    "        return self._travel_time\n",
    "    \n",
    "    def update_travel_time(self):\n",
    "        self._travel_time = 0\n",
    "        for link in self._links:\n",
    "            self._travel_time += link.travel_time\n",
    "            \n",
    "    def __str__(self):\n",
    "        return self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self, paths, links):\n",
    "        self.paths = paths\n",
    "        self.links = links\n",
    "    \n",
    "    def update(self):\n",
    "        for link in self.links:\n",
    "            link.update_travel_time()\n",
    "        for path in self.paths:\n",
    "            path.update_travel_time()\n",
    "            \n",
    "    def update_av(self, avs):\n",
    "        for path in self.paths:\n",
    "            path.flow = 0\n",
    "        for av in avs:\n",
    "            av.path.flow += av.flow\n",
    "        self.update()\n",
    "        for av in avs:\n",
    "            av.give_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = link('ab', 1, 1/100)\n",
    "ac = link('ac', 2, 0)\n",
    "bc = link('bc', 0.25, 0)\n",
    "bd = link('bd', 2, 0)\n",
    "cd = link('cd', 1, 1/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd = path('abcd', [ab, bc, cd])\n",
    "abd = path('abd', [ab, bd])\n",
    "acd = path('acd', [ac, cd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "braess = network([abd, acd, abcd], [ab, ac, bc, bd, cd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "braess.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.75, 3.75, 3.75]\n"
     ]
    }
   ],
   "source": [
    "#Nash equilibrium\n",
    "abcd.flow = 50\n",
    "abd.flow = 25\n",
    "acd.flow = 25\n",
    "braess.update()\n",
    "print([path.get_travel_time() for path in braess.paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.5, 3.5, 3.25]\n"
     ]
    }
   ],
   "source": [
    "#social optimum\n",
    "abcd.flow = 0\n",
    "abd.flow = 50\n",
    "acd.flow = 50\n",
    "braess.update()\n",
    "print([path.get_travel_time() for path in braess.paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change this\n",
    "# 1. to do Igor experiment \n",
    "class autonomous_vehicle:\n",
    "    # p = 0.5\n",
    "    def __init__(self, name, flow):\n",
    "        self.name = name\n",
    "        self.path = None\n",
    "        self.reward = 0\n",
    "        self.flow = flow\n",
    "    \n",
    "    def path_choice(self, path):\n",
    "        if self.path == None:\n",
    "            self.path = path\n",
    "        # the following condition makes the system converges toward Nash\n",
    "        # change this condition to make an faster convergence toward Nash\n",
    "        p = abs(self.path.get_travel_time() - path.get_travel_time()) / self.path.get_travel_time()\n",
    "        self.path = (path if np.random.rand() < p else self.path)\n",
    "    \n",
    "    def give_reward(self):\n",
    "        # add here a NN which choose the path given the reward\n",
    "        self.reward = - self.path.get_travel_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "av1 = autonomous_vehicle('1', 25)\n",
    "av2 = autonomous_vehicle('2', 25)\n",
    "av3 = autonomous_vehicle('3', 25)\n",
    "av4 = autonomous_vehicle('4', 25)\n",
    "\n",
    "avs = [av1, av2, av3, av4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    best_path = [x for _,x in sorted([(path.get_travel_time(),path) for path in braess.paths],  key=lambda tup: tup[0])][0]\n",
    "    #print([(str(path), path.flow, path.get_travel_time()) for path in braess.paths])\n",
    "    #print(av2.p)\n",
    "    for av in avs:\n",
    "        av.path_choice(best_path)\n",
    "\n",
    "    braess.update_av(avs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acd', 'abd', 'abcd', 'abcd']\n",
      "[('abd', 25, 3.75), ('acd', 25, 3.75), ('abcd', 50, 3.75)]\n"
     ]
    }
   ],
   "source": [
    "print([str(av.path) for av in avs])\n",
    "print([(str(path), path.flow, path.get_travel_time()) for path in braess.paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for av in avs:\n",
    "    av.path = acd\n",
    "braess.update_av(avs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Description\n",
    "The environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Routing Environment \n",
    "class RoutingEnv():\n",
    "    \"\"\"A partially observed routing environment in which cars are choosing routing paths each day.\n",
    "    \n",
    "    States\n",
    "        The states (what's observed) are the number of cars on each path and messages from others. \n",
    "    Actions\n",
    "        Actions are the path choice for each vehicle and the communication among them.\n",
    "    Rewards\n",
    "        Each vehicle's goal is to minimize their own travel time and eventually reduce their marginal cost of \n",
    "        their choices on each driver. Thus, the cost function is: \n",
    "            (1) the amount of time on your own route \n",
    "            (2) the cost of your route choice on the other drivers \n",
    "                    (how much the travel times of other drivers has increased.\n",
    "    Termination\n",
    "        A rollout is terminated if the time horizon is reached.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"A routing environment should consist of a road network.\"\"\"\n",
    "        # Create the roads\n",
    "        ab = link('ab', 1, 1/100)\n",
    "        ac = link('ac', 2, 0)\n",
    "        bc = link('bc', 0.25, 0)\n",
    "        bd = link('bd', 2, 0)\n",
    "        cd = link('cd', 1, 1/100)\n",
    "        roads = [ab, ac, bc, bd, cd]\n",
    "        \n",
    "        # Create the possible routes\n",
    "        abcd = path('abcd', [ab, bc, cd])\n",
    "        abd = path('abd', [ab, bd])\n",
    "        acd = path('acd', [ac, cd])\n",
    "        paths = [abd, acd, abcd]\n",
    "        \n",
    "        # Put the roads and the routes in a network\n",
    "        town = network(paths, links)\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    def action_space(self):\n",
    "        ##############################################################\n",
    "        # specify dimensions and properties of the action space here #\n",
    "        ##############################################################\n",
    "        return  ### FILL IN ###\n",
    "\n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        #############################################################\n",
    "        # specify dimensions and properties of the state space here #\n",
    "        #############################################################\n",
    "        return  ### FILL IN ###\n",
    "    \n",
    "    def get_state(self, **kwargs):\n",
    "        ####################################\n",
    "        # specify desired state space here #\n",
    "        ####################################\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Restarts the environment.\"\"\"\n",
    "        return obs_dict\n",
    "    \n",
    "    def step(self, actions):\n",
    "        \"\"\"Moves the environment forward one step by applying the actions of the agents.\"\"\"\n",
    "        for agent, rl_action in action.items():\n",
    "            # Apply the action\n",
    "            # Compute the rewards \n",
    "            # Get the next state\n",
    "        return\n",
    "        \n",
    "    def compute_reward(self, state, rl_actions, **kwargs):\n",
    "        \"\"\"Computes the reward of each action for the current state.\"\"\"\n",
    "        return \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
